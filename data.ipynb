{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertTokenizer\n",
    "from models import Transformer\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leeht\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MarianTokenizer(name_or_path='Helsinki-NLP/opus-mt-en-fr', vocab_size=59514, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t59513: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>she ordered him to clean up his room.</td>\n",
       "      <td>elle lui ordonna de nettoyer sa chambre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>are you sure you don't want coffee?</td>\n",
       "      <td>êtes-vous certaine de ne pas vouloir de café ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm sorry, i can't come today.</td>\n",
       "      <td>je suis désolé, je ne peux pas venir aujourd'hui.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this isn't my first time riding a bicycle.</td>\n",
       "      <td>ce n'est pas la première fois que je fais du v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>somebody hit me.</td>\n",
       "      <td>j’ai été frappé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209457</th>\n",
       "      <td>i don't want to go.</td>\n",
       "      <td>je ne veux pas y aller.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209458</th>\n",
       "      <td>did you send them?</td>\n",
       "      <td>les avez-vous envoyés ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209459</th>\n",
       "      <td>there is no antidote.</td>\n",
       "      <td>il n'y a pas d'antidote.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209460</th>\n",
       "      <td>i don't think they're married.</td>\n",
       "      <td>je ne pense pas qu'ils soient mariés.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209461</th>\n",
       "      <td>i'm sure you won't disappoint me.</td>\n",
       "      <td>je suis certaine que vous ne me décevrez pas.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209462 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               src  \\\n",
       "0            she ordered him to clean up his room.   \n",
       "1              are you sure you don't want coffee?   \n",
       "2                   i'm sorry, i can't come today.   \n",
       "3       this isn't my first time riding a bicycle.   \n",
       "4                                 somebody hit me.   \n",
       "...                                            ...   \n",
       "209457                         i don't want to go.   \n",
       "209458                          did you send them?   \n",
       "209459                       there is no antidote.   \n",
       "209460              i don't think they're married.   \n",
       "209461           i'm sure you won't disappoint me.   \n",
       "\n",
       "                                                      tar  \n",
       "0                elle lui ordonna de nettoyer sa chambre.  \n",
       "1          êtes-vous certaine de ne pas vouloir de café ?  \n",
       "2       je suis désolé, je ne peux pas venir aujourd'hui.  \n",
       "3       ce n'est pas la première fois que je fais du v...  \n",
       "4                                        j’ai été frappé.  \n",
       "...                                                   ...  \n",
       "209457                            je ne veux pas y aller.  \n",
       "209458                            les avez-vous envoyés ?  \n",
       "209459                           il n'y a pas d'antidote.  \n",
       "209460              je ne pense pas qu'ils soient mariés.  \n",
       "209461      je suis certaine que vous ne me décevrez pas.  \n",
       "\n",
       "[209462 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_preprocess.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.max_len = max_len\n",
    "        self.src = tokenizer(list(self.data['src']), padding=True, truncation=True, max_length = self.max_len, return_tensors='pt').input_ids\n",
    "        self.tar = tokenizer(['<s>' + s for s in self.data['tar']], padding=True, truncation=True, max_length = self.max_len, return_tensors='pt').input_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.src[idx], self.tar[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_preprocess.csv')\n",
    "tokenizer.add_special_tokens({'bos_token':'<s>'})\n",
    "custom_ds = CustomDataset(train, tokenizer, 120)\n",
    "train_ds, valid_ds = torch.utils.data.random_split(custom_ds, [0.8, 0.2])\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54591\n",
      "tensor([ 2942,  2408,   453,     3,     0, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513])\n",
      "move along now.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "tensor([59514,    15, 18619,   643,  3954,   282,     3,     0, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513])\n",
      "<s> avance maintenant.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "i = 6\n",
    "idx = train_ds.indices[i]\n",
    "print(idx)\n",
    "src_text, trg_text = custom_ds.__getitem__(idx)\n",
    "print(src_text)\n",
    "print(tokenizer.decode(src_text))\n",
    "print(trg_text)\n",
    "print(tokenizer.decode(trg_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59514"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59513"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size + 1\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 120\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Transformer(vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout, batch_size, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder_embedding): InputEmbeddings(\n",
      "    (embedding): Embedding(59515, 512)\n",
      "  )\n",
      "  (decoder_embedding): InputEmbeddings(\n",
      "    (embedding): Embedding(59515, 512)\n",
      "  )\n",
      "  (positional_encoding): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder_layers): ModuleList(\n",
      "    (0-5): 6 x EncoderLayer(\n",
      "      (self_attn): MultiHeadAttentionLayer(\n",
      "        (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (fc_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (decoder_layers): ModuleList(\n",
      "    (0-5): 6 x DecoderLayer(\n",
      "      (self_attn): MultiHeadAttentionLayer(\n",
      "        (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (cross_attn): MultiHeadAttentionLayer(\n",
      "        (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (fc_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=59515, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 82])\n",
      "tensor([   86,    55, 13131,   143,   541,    12,  1903, 43110,    54,     0,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513])\n",
      "will you teach me how to play chess?</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "torch.Size([32, 120])\n",
      "tensor([59514,    27,  2731,   265,    21,   973,  2130,   251,     6,  4786,\n",
      "         6262,  7574,    17, 24089,  9840,    56,  2445,  4639,   222,     9,\n",
      "           99,     0, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "        59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513])\n",
      "<s> pourriez-vous m'apprendre à jouer aux échecs?</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "src_texts, tar_texts = next(iter(train_dl))\n",
    "print(src_texts.shape)\n",
    "print(src_texts[0])\n",
    "print(tokenizer.decode(src_texts[0]))\n",
    "print(tar_texts.shape)\n",
    "print(tar_texts[0])\n",
    "print(tokenizer.decode(tar_texts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 82])\n",
      "torch.Size([32, 120])\n",
      "torch.Size([32, 82])\n",
      "torch.Size([32, 120])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_dl):\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_texts = src_texts.to(device)\n",
    "tar_texts = tar_texts.to(device)\n",
    "output, attention = model(src_texts, tar_texts[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 119, 59515])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59515"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3808, 59515])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.contiguous().view(-1, vocab_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 119, 82])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3808])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_texts[:, 1:].contiguous().view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.1801, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(output.contiguous().view(-1, vocab_size), tar_texts[:, 1:].contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
